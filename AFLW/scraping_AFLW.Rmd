---
title: "Scraping AFLW data"
author: "Peter Hickey"
date: "26/10/2017"
output:
  github_document:
    toc: true
    toc_depth: 2
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Here's a (amazingly) simple example to get the 'default' table that is shown 
when you visit [http://www.afl.com.au/womens/matches/stats](http://www.afl.com.au/womens/matches/stats). The result is returned as a _data.frame_.

```{r}
library(xml2)
library(rvest)

url <- "http://www.afl.com.au/womens/matches/stats"
aflw <- xml2::read_html(url)
tab <- rvest::html_node(aflw, "table")
x <- rvest::html_table(tab)
x
```

After looking more closely at the source, I realised there are in fact 2 tables
on this page: `team-stats` and `player-stats`

```{r}
tabs <- rvest::html_nodes(aflw, "table")
teams_tab <- rvest::html_table(tabs[[1]])
teams_tab
players_tab <- rvest::html_table(tabs[[2]], fill = TRUE)
players_tab
```

## Process the team data

```{r}
x <- lapply(1:3, function(i) {
  p <- read_html(paste0("html_pages/team/p", i ,".html"))
  ptabs <- rvest::html_nodes(p, "table")
  teams_ptab <- rvest::html_table(ptabs[[1]])
  colnames(teams_ptab) <- paste0(colnames(teams_ptab),"_", teams_ptab[1, ])
  teams_ptab <- teams_ptab[-1, ] 
  teams_ptab
})
team_tab <- Reduce(merge, x)
colnames(team_tab)[1] <- "Club"

write.csv(team_tab, "data/teams.csv", quote = FALSE, row.names = FALSE)
```

## Process the player data

```{r}

y <- lapply(1:3, function(i) {
  players_ptab <- read.csv(paste0("data_raw/players_tab", i ,".csv"), check.names =      FALSE,stringsAsFactors = FALSE, quote ="", header = TRUE)
  colnames(players_ptab) <- paste0(colnames(players_ptab),"_", players_ptab[1, ])
  players_ptab <- players_ptab[-1, ]
  players_ptab$Player_ <- sub("[0-9]*\\s*", "", players_ptab$Player_)
  players_ptab
})
  
players_tab <- Reduce(merge, y)
colnames(players_tab)[1:2] <- c("Player", "Club")

write.csv(players_tab, "data/players.csv", quote = FALSE, row.names = FALSE)
```

